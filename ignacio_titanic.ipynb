{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import ks_2samp\n",
    "#from fancyimpute import KNN\n",
    "import knnimpute\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import plot_importance\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/titanic_train.csv')\n",
    "print(f'Number of observations {train_data.shape[0]}, number of features {train_data.shape[1]}')\n",
    "print(train_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there any missing values? At what fraction\n",
    "miss_vals = pd.concat([train_data.count(), train_data.isnull().sum(), train_data.isnull().sum()/train_data.shape[0]], axis=1)\n",
    "miss_vals.columns = ['Ntot', 'No. NA', 'NA Frac.']\n",
    "print(miss_vals)\n",
    "print('\\n')\n",
    "print(f'Duplicate records (wrt PassengerId) {train_data.PassengerId.duplicated().sum()}')\n",
    "fig, axs = plt.subplots(1,1)\n",
    "axs.bar(miss_vals.index, height=miss_vals['No. NA'])\n",
    "axs.set_title('NA values count')\n",
    "axs.tick_params(rotation=90)\n",
    "axs.semilogy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PassengerId will be our index\n",
    "train_data.set_index('PassengerId', inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check cardinality of int and object values\n",
    "for k, val in train_data.dtypes.iteritems():\n",
    "    if val == 'float64':\n",
    "        continue\n",
    "    # Ticket has high cardinality\n",
    "    if k == 'Ticket' or k == 'Name':\n",
    "        continue\n",
    "    print(f'{k} has {train_data[k].unique().shape[0]} values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there's outliers/non-sensical values\n",
    "print(train_data.describe())\n",
    "\n",
    "# Do some exploratory plots\n",
    "fig, axs = plt.subplots(5,2)\n",
    "axs[0,0].bar(train_data['Survived'].value_counts().index, height=train_data['Survived'].value_counts())\n",
    "axs[0,0].set_title('Survived')\n",
    "axs[0,1].bar(train_data['Pclass'].value_counts().index, height=train_data['Pclass'].value_counts())\n",
    "axs[0,1].set_title('Pclass')\n",
    "axs[1,0].bar(train_data['Sex'].value_counts().index, height=train_data['Sex'].value_counts())\n",
    "axs[1,0].set_title('Sex')\n",
    "axs[1,1].hist(train_data['Age'].dropna())\n",
    "axs[1,1].set_title('Age')\n",
    "axs[2,0].bar(train_data['SibSp'].value_counts().index, height=train_data['SibSp'].value_counts())\n",
    "axs[2,0].set_title('SibSp')\n",
    "axs[2,1].bar(train_data['Parch'].value_counts().index, height=train_data['Parch'].value_counts())\n",
    "axs[2,1].set_title('Parch')\n",
    "axs[3,0].hist(train_data['Fare'])\n",
    "axs[3,0].set_title('Fare')\n",
    "axs[3,1].bar(train_data['Embarked'].value_counts().index, height=train_data['Embarked'].value_counts())\n",
    "axs[3,1].set_title('Embarked')\n",
    "axs[4,0].bar(train_data['Cabin'].value_counts().index, height=train_data['Cabin'].value_counts())\n",
    "axs[4,0].set_title('Cabin')\n",
    "plt.subplots_adjust(hspace=1.5)\n",
    "plt.show()\n",
    "fig.savefig('titanic_eda.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Survived ratio')\n",
    "print('{}'.format(train_data['Survived'].value_counts(normalize=True)))\n",
    "print('train data set is decently balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'Cabin' feature since > 77% is missing\n",
    "train_data.drop('Cabin', inplace=True, axis=1)\n",
    "# Assign records with NA Embarked the most common value\n",
    "train_data.loc[train_data['Embarked'].isnull(),'Embarked'] = train_data['Embarked'].value_counts().sort_values().index[-1]\n",
    "print(train_data.shape)\n",
    "print(train_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check 'Name' variable and try to reduce number of categories, i.e. get the title (Mr., Ms, Mrs, Dr. etc)\n",
    "print(train_data.loc[:10,'Name'])\n",
    "name_list = []\n",
    "train_data.loc[:, 'Name'].apply(lambda x: name_list.extend([j.lower().strip('.') for j in x.split()]))\n",
    "c = Counter(name_list)\n",
    "print(c.most_common()[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform Name feature to Title feature\n",
    "train_data.loc[:, 'Name'] = train_data.loc[:, 'Name'].apply(lambda x: x.lower())\n",
    "titles = ['mr', 'miss', 'mrs', 'master', 'dr', 'rev']\n",
    "def get_title(fullname, titles=titles):\n",
    "    for j in fullname.lower().split():\n",
    "        if j.strip('.') in titles:\n",
    "            return j.strip('.')\n",
    "        else:\n",
    "            continue\n",
    "    return 'Unknown'\n",
    "train_data['Title'] = train_data.loc[:, 'Name'].apply(get_title)\n",
    "# We don't need 'Name' anymore\n",
    "train_data.drop('Name', axis=1, inplace=True)\n",
    "cat_vars = train_data.dtypes[train_data.dtypes=='O'].index.values\n",
    "num_cat = train_data.dtypes[train_data.dtypes!='O'].index.values\n",
    "print(f'Categorical variables {cat_vars}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature types\n",
    "print(train_data.dtypes)\n",
    "# Check only object type features and check categories\n",
    "cat_vars = train_data.dtypes[train_data.dtypes=='O'].index.values\n",
    "for cat in cat_vars:\n",
    "    print(f'{cat} has {train_data[cat].unique().shape} categories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create one-hot encoded dataset\n",
    "def do_onehot(sourcedata, cat_vars=cat_vars):\n",
    "    df_dest = sourcedata.copy(deep=True)\n",
    "    for cat in cat_vars:\n",
    "        # Ticket has too many values\n",
    "        if cat == 'Ticket':\n",
    "            df_dest.drop(cat, axis=1, inplace=True)\n",
    "            continue\n",
    "        df_dest = df_dest.merge(pd.get_dummies(sourcedata[cat], prefix=cat), left_index=True, right_index=True)\n",
    "        df_dest.drop(cat, axis=1, inplace=True)\n",
    "    return df_dest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_full_cat = do_onehot(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_full_cat.isnull().sum())\n",
    "print(train_full_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a closer look at Age. Create subset with full Age data and subset with NA Age\n",
    "train_agedata = train_data.loc[train_data['Age'].dropna().index]\n",
    "train_naagedata = train_data.loc[train_data['Age'].isnull(),:]\n",
    "# Do not use Survived for age imputation\n",
    "train_agedata.drop('Survived', axis=1, inplace=True)\n",
    "train_naagedata.drop('Survived', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_agedata.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age distributions women vs men\n",
    "fig, axs = plt.subplots(1,1)\n",
    "axs.hist(train_agedata.loc[train_agedata['Sex']=='male', 'Age'], label='men', density=True)\n",
    "axs.hist(train_agedata.loc[train_agedata['Sex']=='female', 'Age'], label='women', density=True)\n",
    "axs.legend()\n",
    "axs.set_title('Titanic train data')\n",
    "axs.set_xlabel('Age')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-sample Kolmogorov-Smirnov test to check whether Age distribution between 'male' and 'female' differ\n",
    "ks_age = ks_2samp(train_agedata.loc[train_agedata['Sex']=='male', 'Age'], train_agedata.loc[train_agedata['Sex']=='female', 'Age'])\n",
    "print(f'ks stat: {ks_age[0]}; p-value {ks_age[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot categorical variables of data w/ Age and with NA Age\n",
    "fig, axs = plt.subplots(2,3, figsize=(15,10))\n",
    "i, j = 0, 0\n",
    "for cat in cat_vars.tolist() + ['SibSp', 'Parch']:\n",
    "    if cat == 'Ticket':\n",
    "        continue\n",
    "    vcount_age = train_agedata[cat].value_counts()\n",
    "    axs[i,j].bar(vcount_age.index, height=vcount_age/train_agedata.shape[0],\n",
    "                 label='w/ Age')\n",
    "    vcount = train_naagedata[cat].value_counts()\n",
    "    for val in train_agedata[cat].unique():\n",
    "        if val not in vcount.index:\n",
    "            vcount[val] = 0\n",
    "    axs[i,j].bar(vcount.index, height=vcount/train_naagedata.shape[0],\n",
    "                 fill=False, hatch='/', label='na Age')\n",
    "    axs[i,j].set_title(cat)\n",
    "    if cat == 'Title':\n",
    "        axs[i,j].tick_params(rotation=45)\n",
    "    axs[i,j].legend()\n",
    "    if j == 2:\n",
    "        j=0\n",
    "        i+=1\n",
    "    else:\n",
    "        j+=1\n",
    "# Handle 'Fare' separately since it's numerical\n",
    "axs[1,2].hist(train_agedata['Fare'], density=True, label='w/ Age')\n",
    "axs[1,2].hist(train_naagedata['Fare'], density=True, \n",
    "              fill=False, hatch='/', label='na Age')\n",
    "axs[1,2].legend()\n",
    "axs[1,2].set_title('Fare')\n",
    "plt.subplots_adjust(hspace=0.2)\n",
    "plt.tight_layout()\n",
    "fig.savefig('naage_vs_age.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is there are relation between missing age and Sex?\n",
    "# Run a chi2 test on missing Age data vs Sex\n",
    "naage_sex = np.column_stack([np.concatenate([train_agedata['Sex'].values, train_naagedata['Sex'].values]),\n",
    "                 np.r_[np.zeros(shape=(train_agedata.shape[0])), np.ones(shape=(train_naagedata.shape[0]))]])\n",
    "contingency_tab = pd.crosstab(naage_sex[:,0], naage_sex[:,1])\n",
    "contingency_tab.columns = ['Age ok', 'NA Age']\n",
    "print(contingency_tab)\n",
    "chi2_test = chi2_contingency(contingency_tab)\n",
    "print(f'chi test statistic {chi2_test[0]:0.5f}, p-value: {chi2_test[1]:0.5f}')\n",
    "print('p-value < 0.05 do not reject null hypothesis') \n",
    "print('missing Age values has no gender bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is there any correlation between port of embarkation and missing age?\n",
    "# Run a chi2 test on missing Age data vs Embarked\n",
    "naage_embarked = np.column_stack([np.concatenate([train_agedata['Embarked'].values, train_naagedata['Embarked'].values]),\n",
    "                 np.r_[np.zeros(shape=(train_agedata.shape[0])), np.ones(shape=(train_naagedata.shape[0]))]])\n",
    "contingency_tab = pd.crosstab(naage_embarked[:,0], naage_embarked[:,1])\n",
    "contingency_tab.columns = ['Age ok', 'NA Age']\n",
    "print(contingency_tab)\n",
    "chi2_test = chi2_contingency(contingency_tab)\n",
    "print(f'chi test statistic {chi2_test[0]:0.5f}, p-value: {chi2_test[1]:0.5f}')\n",
    "print('p-value < 0.05 reject null hypothesis - missing Age values correlates with port of embarkation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_agedata = do_onehot(train_agedata)\n",
    "onehot_naagedata = do_onehot(train_naagedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute Age with KNN - test performance on subset with good Age data\n",
    "def impute_age(indata, k=10, frac=0.15, mode='test'):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "       indata (DataFrame): input data\n",
    "       k (int):            k neareast neighbors\n",
    "       frac (float):       fraction of data to use for testing\n",
    "       mode (str):         are we testing on imputing unseen data\n",
    "    \n",
    "    Returns:\n",
    "       dict with data, used indices, true_values, rmse\n",
    "    \"\"\"\n",
    "    if mode == 'test':\n",
    "        test_idx = np.random.choice(indata.index, size=int(indata.shape[0]*frac))\n",
    "        age_bkp = indata.loc[test_idx, 'Age'].copy(deep=True)\n",
    "        indata.loc[test_idx, 'Age'] = np.nan\n",
    "    indata_imputed = pd.DataFrame(knnimpute.knn_impute_reference(indata.values,\n",
    "                                                                 np.isnan(indata.values), k),\n",
    "                                 columns=indata.columns, index=indata.index)\n",
    "    if mode != 'test':\n",
    "        return {'data': indata_imputed}\n",
    "    \n",
    "    indata.loc[test_idx,'Age'] = age_bkp\n",
    "    rmse = np.mean((indata_imputed.loc[test_idx, 'Age'] - age_bkp)**2)**0.5\n",
    "    return {'data': indata_imputed, 'test_idx': test_idx, 'orig_age': age_bkp, 'rmse': rmse}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Age imputation with onehot data and k=10...50\n",
    "rmse_k = {}\n",
    "for k in range(10, 50):\n",
    "    imp = impute_age(onehot_agedata, k=k)\n",
    "    rmse_k[k] = imp['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Age imputation with categorical age data and k=10...50\n",
    "le_dict = defaultdict(LabelEncoder)\n",
    "rmse_k_labenc = {}\n",
    "labenc_agedata = train_agedata.apply(lambda x: le_dict[x.name].fit_transform(x))\n",
    "for k in range(1, 50):\n",
    "    imp = impute_age(labenc_agedata, k=k)\n",
    "    rmse_k_labenc[k] = imp['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute Age from mean distribution\n",
    "test_idx = np.random.choice(train_agedata.index, size=int(train_agedata.shape[0]*0.15))\n",
    "age_bak = train_agedata.loc[test_idx, 'Age'].copy(deep=True)\n",
    "rmse_mean = np.mean((age_bak - np.mean(train_agedata.loc[~train_agedata.index.isin(test_idx), 'Age']))**2)**0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot RMSE vs k values, compare one-hot encoding with simple label encoding\n",
    "# and with mean value encoding\n",
    "plt.plot(rmse_k.keys(), rmse_k.values(), label='one hot')\n",
    "plt.plot(rmse_k_labenc.keys(), rmse_k_labenc.values(), label='label encoder')\n",
    "plt.plot([0,50], [rmse_mean, rmse_mean], label='mean impute')\n",
    "best_kval = min(rmse_k, key=rmse_k.get)\n",
    "plt.text(2, 20, f'best k value: {best_kval} (w/ one hot encoding)')\n",
    "plt.legend()\n",
    "plt.title('Age knn imputation rmse vs k')\n",
    "plt.xlabel('k neighbors')\n",
    "plt.ylabel('rmse')\n",
    "plt.savefig('age_impute_knn.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute 'Age' with one-hot encoded data with knn and best k\n",
    "oh_train_data = do_onehot(train_data)\n",
    "# We can drop the 'Sex_male' column and just keep 'Sex_female'\n",
    "oh_train_data.drop('Sex_male', axis=1, inplace=True)\n",
    "print(oh_train_data.columns)\n",
    "oh_train_data_age_impute = knnimpute.knn_impute_reference(oh_train_data.values,\n",
    "                                                         np.isnan(oh_train_data.values),\n",
    "                                                         k=best_kval)\n",
    "oh_train_data_age_impute = pd.DataFrame(oh_train_data_age_impute, columns=oh_train_data.columns,\n",
    "                                       index=oh_train_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Age distribution before and after imputation\n",
    "plt.hist(oh_train_data_age_impute['Age'], density=True, label='imputed')\n",
    "plt.hist(train_data['Age'].dropna(), density=True, fill=False, hatch='/', label='orig')\n",
    "plt.xlabel('Age')\n",
    "plt.title('Age pdf before and after imputation')\n",
    "plt.legend()\n",
    "plt.savefig('age_impute.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a 2 sample Kolmogorov-Smirnov test \n",
    "# to check whether the distributions are similar\n",
    "age_ks_test = ks_2samp(train_data['Age'].dropna(), oh_train_data_age_impute['Age'])\n",
    "print(f'KS stat: {age_ks_test[0]:0.6f}, p-value: {age_ks_test[1]:0.6f}')\n",
    "print('Cannot reject null-hypo, samples come \\nfrom same distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbclf = XGBClassifier()\n",
    "parameters = {'objective':['binary:logistic'],\n",
    "              'learning_rate': [0.05, 0.1, 1.0],\n",
    "              'max_depth': [2,3,4,6],\n",
    "              'min_child_weight': [5, 7, 9, 11],\n",
    "              'gamma': [0, 0.5, 1, 3],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.8],\n",
    "              'colsample_bytree': [0.7, 1.],\n",
    "              'n_estimators': [100, 200, 400, 600, 800],\n",
    "              'missing': [-1],\n",
    "              'reg_alpha': [0],\n",
    "              'reg_lambda': [1],\n",
    "              'seed': [1234]}\n",
    "\n",
    "clf_age_impute = GridSearchCV(xgbclf, parameters, n_jobs=5,\n",
    "                              cv=StratifiedKFold(n_splits=5, shuffle=True, \n",
    "                                                 random_state=1234), \n",
    "                              scoring=['accuracy','roc_auc'],\n",
    "                              verbose=2, refit='roc_auc',\n",
    "                              return_train_score=True, iid=False)\n",
    "\n",
    "clf_age_na = GridSearchCV(xgbclf, parameters, n_jobs=5,\n",
    "                          cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=1234), \n",
    "                          scoring=['accuracy','roc_auc'], verbose=2, refit='roc_auc',\n",
    "                          return_train_score=True, iid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_age_impute.fit(oh_train_data_age_impute.drop('Survived', axis=1), oh_train_data_age_impute['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oh_train_data.loc[oh_train_data['Age'].isnull(), 'Age'] = -1\n",
    "clf_age_na.fit(oh_train_data.drop('Survived', axis=1), oh_train_data['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,1, figsize=(15,10))\n",
    "axs[0].plot(clf_age_impute.cv_results_['mean_train_roc_auc'], label='auc - train')\n",
    "axs[0].plot(clf_age_impute.cv_results_['mean_test_roc_auc'], label='auc - test')\n",
    "axs[0].legend()\n",
    "axs[0].set_xlabel('parameter config')\n",
    "axs[0].set_ylabel('AUC')\n",
    "axs[0].set_ylim([0.85, 1.02])\n",
    "axs[0].text(0, 1.01, 'best config {}: {:0.3f}'.format(np.argmax(clf_age_impute.cv_results_['mean_test_roc_auc']),\n",
    "                                                max(clf_age_impute.cv_results_['mean_test_roc_auc'])),\n",
    "           fontsize=12)\n",
    "axs[1].plot(clf_age_impute.cv_results_['mean_train_accuracy'], label='acc. - train')\n",
    "axs[1].plot(clf_age_impute.cv_results_['mean_test_accuracy'], label='acc. - test')\n",
    "axs[1].legend()\n",
    "axs[1].set_ylabel('Acc.')\n",
    "axs[1].set_xlabel('parameter config')\n",
    "axs[1].set_ylim([0.775, 1.02])\n",
    "axs[1].text(0, 1., 'best config {}: {:0.3f}'.format(np.argmax(clf_age_impute.cv_results_['mean_test_accuracy']),\n",
    "                                            max(clf_age_impute.cv_results_['mean_test_accuracy'])),\n",
    "           fontsize=12)\n",
    "#plt.subplots_adjust(hspace=0.7)\n",
    "fig.suptitle('One-hot encoded w/ kNN Age imputation')\n",
    "fig.savefig('PerfGridSearchCV_Acc.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,1, figsize=(15,10))\n",
    "axs[0].plot(clf_age_na.cv_results_['mean_train_roc_auc'], label='auc - train')\n",
    "axs[0].plot(clf_age_na.cv_results_['mean_test_roc_auc'], label='auc - test')\n",
    "axs[0].legend()\n",
    "axs[0].set_xlabel('parameter config')\n",
    "axs[0].set_ylabel('AUC')\n",
    "axs[0].set_ylim([0.82, 1.02])\n",
    "axs[0].text(0, 1.005, 'best config {}: {:0.3f}'.format(np.argmax(clf_age_na.cv_results_['mean_test_roc_auc']),\n",
    "                                                max(clf_age_na.cv_results_['mean_test_roc_auc'])),\n",
    "           fontsize=12)\n",
    "axs[1].plot(clf_age_na.cv_results_['mean_train_accuracy'], label='acc. - train')\n",
    "axs[1].plot(clf_age_na.cv_results_['mean_test_accuracy'], label='acc. - test')\n",
    "axs[1].legend()\n",
    "axs[1].set_ylabel('Acc.')\n",
    "axs[1].set_xlabel('parameter config')\n",
    "axs[1].set_ylim([0.775, 1.02])\n",
    "axs[1].text(10, 0.99, 'best config {}: {:0.3f}'.format(np.argmax(clf_age_impute.cv_results_['mean_test_accuracy']),\n",
    "                                            max(clf_age_impute.cv_results_['mean_test_accuracy'])),\n",
    "           fontsize=12)\n",
    "fig.suptitle('One-hot encoded w/o Age imputation')\n",
    "fig.savefig('PerfGridSearchCV_AUC.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_error = []\n",
    "results = {}\n",
    "xgbbest = clf_age_impute.best_estimator_\n",
    "print(xgbbest.get_params)\n",
    "train_error = np.zeros(shape=(xgbbest.n_estimators,), dtype=np.float32)\n",
    "train_logloss = np.zeros(shape=(xgbbest.n_estimators,), dtype=np.float32)\n",
    "test_error = np.zeros(shape=(xgbbest.n_estimators,), dtype=np.float32)\n",
    "test_logloss = np.zeros(shape=(xgbbest.n_estimators,), dtype=np.float32)\n",
    "fpr_folds = []\n",
    "tpr_folds = []\n",
    "thr_folds = []\n",
    "for train_idx, test_idx in clf_age_impute.cv.split(oh_train_data_age_impute.drop('Survived', axis=1), oh_train_data_age_impute['Survived']):\n",
    "    # get the loss for train and test folds\n",
    "    eval_set = [(oh_train_data_age_impute.drop('Survived', axis=1).values[train_idx,:],\n",
    "                oh_train_data_age_impute['Survived'].values[train_idx]),\n",
    "               (oh_train_data_age_impute.drop('Survived', axis=1).values[test_idx,:],\n",
    "                oh_train_data_age_impute['Survived'].values[test_idx])]\n",
    "    xgbbest.fit(oh_train_data_age_impute.drop('Survived', axis=1).values[train_idx,:],\n",
    "               oh_train_data_age_impute['Survived'].values[train_idx], eval_metric=['logloss', 'error'],\n",
    "              eval_set=eval_set, verbose=False)\n",
    "    results = xgbbest.evals_result()\n",
    "    train_error += np.array(results['validation_0']['error'])\n",
    "    train_logloss += np.array(results['validation_0']['logloss'])\n",
    "    test_error += np.array(results['validation_1']['error'])\n",
    "    test_logloss += np.array(results['validation_1']['logloss'])\n",
    "    fpr_, tpr_, thr_ = roc_curve(oh_train_data_age_impute['Survived'].values[test_idx],\n",
    "                             xgbbest.predict_proba(oh_train_data_age_impute.drop('Survived', axis=1).values[test_idx])[:,1])\n",
    "    fpr_folds.append(fpr_)\n",
    "    tpr_folds.append(tpr_)\n",
    "    thr_folds.append(thr_)\n",
    "    \n",
    "xgbbest.fit(oh_train_data_age_impute.drop('Survived', axis=1),\n",
    "               oh_train_data_age_impute['Survived'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,1)\n",
    "fig.suptitle('Error on 5 fold splits')\n",
    "axs.plot(train_error/5, label='train')\n",
    "axs.plot(test_error/5, label='test')\n",
    "axs.legend()\n",
    "axs.set_ylabel('Error')\n",
    "axs.set_xlabel('Epoch')\n",
    "fig.savefig('error_vs_epoch.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,1)\n",
    "fig.suptitle('Logloss on 5 fold splits')\n",
    "axs.plot(train_logloss/5, label='train')\n",
    "axs.plot(test_logloss/5, label='test')\n",
    "axs.legend()\n",
    "axs.set_ylabel('Logloss')\n",
    "axs.set_xlabel('Epoch')\n",
    "fig.savefig('logloss_vs_epoch.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_importance(xgbbest, importance_type='gain')\n",
    "plt.savefig('xgboost_feat_imp_gain.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_, tpr_, thr_ = roc_curve(oh_train_data_age_impute['Survived'],\n",
    "                             xgbbest.predict_proba(oh_train_data_age_impute.drop('Survived', axis=1))[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optthr = 0\n",
    "fig, axs = plt.subplots(1,1, figsize=(15,15))\n",
    "for j in range(5):\n",
    "    axs.plot(fpr_folds[j], tpr_folds[j], label=f'fold {j}')\n",
    "    axs.plot([0, 1], [0, 1], 'k--')\n",
    "    optcut = np.argmax(tpr_folds[j] - fpr_folds[j])\n",
    "    optthr += thr_folds[j][optcut]\n",
    "    axs.plot(fpr_folds[j][optcut], tpr_folds[j][optcut], 'o')\n",
    "axs.set_xlabel('False positive rate')\n",
    "axs.set_ylabel('True positive rate')\n",
    "axs.legend()\n",
    "axs.text(0.6, 0.2, 'optimal threshold (avg): {:0.4f}'.format(optthr/5), fontsize=14)\n",
    "optthr /= 5\n",
    "print(optthr)\n",
    "fig.savefig('roc_5fold.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "xgbbest.save_model('titanic_xgbest001.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check test data set\n",
    "titanic_test = pd.read_csv('data/titanic_test.csv')\n",
    "print(titanic_test.isnull().sum())\n",
    "print(f'test sample rows {titanic_test.shape[0]}, features {titanic_test.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_test.set_index('PassengerId', inplace=True, drop=True)\n",
    "titanic_test.drop('Cabin', axis=1, inplace=True)\n",
    "test_naage=titanic_test[titanic_test.loc[:, 'Age'].isnull()].index\n",
    "titanic_test.loc[titanic_test['Fare'].isnull(), 'Fare'] = train_data['Fare'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_test['Title'] = titanic_test.loc[:, 'Name'].apply(get_title)\n",
    "titanic_test.drop('Name', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing 'Age' fields using knn\n",
    "# Combine NA Age rows of test data with good Age train data\n",
    "naage_test = titanic_test.loc[titanic_test['Age'].isnull()]\n",
    "print(naage_test.shape)\n",
    "oh_naage_test = do_onehot(titanic_test).loc[naage_test.index]\n",
    "oh_test_age_pre_impute = oh_naage_test.append(onehot_agedata)\n",
    "print(oh_test_age_pre_impute.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oh_test_age_impute = knnimpute.knn_impute_reference(oh_test_age_pre_impute.values,\n",
    "                                                    np.isnan(oh_test_age_pre_impute.values), best_kval)\n",
    "\n",
    "oh_test_age_impute = pd.DataFrame(oh_test_age_impute, columns=oh_naage_test.columns,\n",
    "                                  index=np.concatenate([naage_test.index, onehot_agedata.index]))\n",
    "titanic_test_age_knn_impute = titanic_test.copy(deep=True)\n",
    "titanic_test_age_knn_impute.loc[naage_test.index, 'Age'] = oh_test_age_impute.loc[naage_test.index, 'Age']\n",
    "print(titanic_test_age_knn_impute.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(titanic_test.Age, density=True, label='test')\n",
    "plt.hist(train_data.Age, density=True, fill=False, hatch='/', label='train')\n",
    "plt.title('Age distribution')\n",
    "plt.legend()\n",
    "plt.xlabel('Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oh_test_data_knn_age = do_onehot(titanic_test_age_knn_impute)\n",
    "oh_test_data_knn_age.drop('Sex_male', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = xgbbest.predict_proba(oh_test_data_knn_age)\n",
    "yhat = (test_pred[:,1]>0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(yhat, index=titanic_test.index, columns=['Survived'])\n",
    "submission.reset_index(inplace=True)\n",
    "print(submission)\n",
    "submission.to_csv('ignacio_xgbtitanic6.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
